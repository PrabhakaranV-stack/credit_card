#CREDIT CARD FRAUD DETECTION
#Import needed packages
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score 
#from sklearn.naive_bayes import GaussianNB 
#from sklearn.dummy import DummyClassifier
#from sklearn.svm import SVC


					#Read the data
data = pd.read_csv('creditcard.csv')
print(data.shape)

			#Find Null Values
data.isnull().values.any()

fraud = data[data['Class'] == 1] 
valid = data[data['Class'] == 0]
print(fraud.shape,valid.shape)
 
					# Split the data into training and testing sets 
xTrain, xTest, yTrain, yTest = train_test_split( 
        xData, yData, test_size = 0.2, random_state = 40)

			"""Model Creation
		 		RANDOM FOREST MODEL CREATIION""" 
rfc = RandomForestClassifier() 
rfc.fit(xTrain, yTrain) 
				
				# predictions 
yPred = rfc.predict(xTest) 
 
acc = accuracy_score(yTest, yPred) 
print("The accuracy of Render forest is {}".format(acc)) 

"""USING OTHER CLASSIFICATION METHODS
#NAVIEBAYES
gnb = GaussianNB()
gnb.fit(xTrain, yTrain)
yPred=gnb.predict(xTest)
acc = accuracy_score(yTest, yPred) 
print("The accuracy of Naive Bayes is {}".format(acc))


#DUMMY CLASSIFIER
dummy = DummyClassifier()
dummy.fit(xTrain, yTrain)
yPred=dummy.predict(xTest)
acc = accuracy_score(yTest, yPred) 
print("The accuracy of Dummy Classifier is {}".format(acc)) 

#SUPPORT VECTOR MACHINE
svm = SVC()
svm.fit(xTrain, yTrain)
yPred=svm.predict(xTest)
acc = accuracy_score(yTest, yPred) 
print("The accuracy of SVM is {}".format(acc))"""

															"""USING DOWN SEIZING METHOD IN THE FOLLOWING 
																						TO IMPROVE THE ACCURACY OF THE MODEL """

# Lets shuffle the data before creating the subsamples
data1 = data.sample(frac=1)

# amount of fraud classes 492 rows.
fraud_data1 = data1.loc[data1['Class'] == 1]
non_fraud_data1 = data1.loc[data1['Class'] == 0][:492]
normal_distributed_data1 = pd.concat([fraud_data1, non_fraud_data1])

# Shuffle dataframe rows
new_data1 = normal_distributed_data1.sample(frac=1, random_state=42)
new_data1.head()

print('Distribution of the Classes in the subsample dataset')
print(new_data1['Class'].value_counts()/len(new_data1))


sns.countplot('Class', data=new_data1)
plt.title('Equally Distributed Classes', fontsize=14)
plt.show()


# Split the data into training and testing sets 
xTrain, xTest, yTrain, yTest = train_test_split( 
        xData, yData, test_size = 0.2, random_state = 40)


# random forest model creation 
rfc = RandomForestClassifier() 
rfc.fit(xTrain, yTrain) 


# predictions 
yPred = rfc.predict(xTest) 

 #CALCULATING ACCURACY
 acc = accuracy_score(yTest, yPred) 
print("The accuracy of Render forest is {}".format(acc)) 